{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist/train-images-idx3-ubyte.gz already exists\n",
      "data/mnist/train-labels-idx1-ubyte.gz already exists\n",
      "data/mnist/t10k-images-idx3-ubyte.gz already exists\n",
      "data/mnist/t10k-labels-idx1-ubyte.gz already exists\n"
     ]
    }
   ],
   "source": [
    "mnist.downloadmnist('data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = mnist.readmnist('data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = mx.io.NDArrayIter(data = train_x, label = train_y, batch_size = batch_size, shuffle = True)\n",
    "test_iter = mx.io.NDArrayIter(data = test_x, label = test_y, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.Variable(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = mx.sym.FullyConnected(data, name = 'fc1', num_hidden = 64)\n",
    "relu1 = mx.sym.Activation(fc1, name = 'relu1', act_type = \"relu\")\n",
    "fc2 = mx.sym.FullyConnected(relu1, name = \"fc2\", num_hidden = 10)\n",
    "out = mx.sym.SoftmaxOutput(fc2, name = \"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"502pt\"\n",
       " viewBox=\"0.00 0.00 214.00 502.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 498)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-498 210,-498 210,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"47\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- fc1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>fc1</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-167 -7.10543e-15,-167 -7.10543e-15,-109 94,-109 94,-167\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- fc1&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>fc1&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-98.5824C47,-85.2841 47,-70.632 47,-58.2967\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-108.887 42.5001,-98.887 47,-103.887 47.0001,-98.887 47.0001,-98.887 47.0001,-98.887 47,-103.887 51.5001,-98.8871 47,-108.887 47,-108.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">784</text>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>relu1</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-276 -7.10543e-15,-276 -7.10543e-15,-218 94,-218 94,-276\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-250.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-235.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;fc1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>relu1&#45;&gt;fc1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-207.582C47,-194.284 47,-179.632 47,-167.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-217.887 42.5001,-207.887 47,-212.887 47.0001,-207.887 47.0001,-207.887 47.0001,-207.887 47,-212.887 51.5001,-207.887 47,-217.887 47,-217.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-188.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- fc2 -->\n",
       "<g id=\"node4\" class=\"node\"><title>fc2</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-385 -7.10543e-15,-385 -7.10543e-15,-327 94,-327 94,-385\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-359.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-344.8\" font-family=\"Times,serif\" font-size=\"14.00\">10</text>\n",
       "</g>\n",
       "<!-- fc2&#45;&gt;relu1 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>fc2&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-316.582C47,-303.284 47,-288.632 47,-276.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-326.887 42.5001,-316.887 47,-321.887 47.0001,-316.887 47.0001,-316.887 47.0001,-316.887 47,-321.887 51.5001,-316.887 47,-326.887 47,-326.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-297.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- softmax_label -->\n",
       "<g id=\"node5\" class=\"node\"><title>softmax_label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"159\" cy=\"-356\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-352.3\" font-family=\"Times,serif\" font-size=\"14.00\">softmax_label</text>\n",
       "</g>\n",
       "<!-- softmax -->\n",
       "<g id=\"node6\" class=\"node\"><title>softmax</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"170,-494 76,-494 76,-436 170,-436 170,-494\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-461.3\" font-family=\"Times,serif\" font-size=\"14.00\">softmax</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;fc2 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>softmax&#45;&gt;fc2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.1082,-427.547C87.3017,-413.741 76.2938,-398.243 67.0986,-385.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.032,-435.887 93.5724,-430.34 100.137,-431.811 97.2411,-427.734 97.2411,-427.734 97.2411,-427.734 100.137,-431.811 100.91,-425.128 103.032,-435.887 103.032,-435.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"97\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\">10</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;softmax_label -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>softmax&#45;&gt;softmax_label</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.713,-426.215C140.333,-412.483 145.463,-397.236 149.729,-384.555\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.459,-435.887 131.382,-424.974 134.053,-431.148 135.647,-426.409 135.647,-426.409 135.647,-426.409 134.053,-431.148 139.913,-427.844 132.459,-435.887 132.459,-435.887\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa3d45787f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can visualize the entire layer by just giving it input size\n",
    "temp_shape = {\"data\" : (batch_size, 784)}\n",
    "mx.viz.plot_network(symbol = out, shape = temp_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = mx.mod.Module(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "['softmax_label']\n",
      "[DataDesc[data,(128, 784),<class 'numpy.float32'>,NCHW]]\n",
      "[DataDesc[softmax_label,(128, 10),<class 'numpy.float32'>,NCHW]]\n"
     ]
    }
   ],
   "source": [
    "print(mod.data_names)\n",
    "print(mod.label_names)\n",
    "print(train_iter.provide_data)\n",
    "print(train_iter.provide_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.bind(data_shapes = train_iter.provide_data, label_shapes = train_iter.provide_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.init_params(initializer = mx.init.Xavier(magnitude = 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.init_optimizer(optimizer = 'sgd', optimizer_params = (('learning_rate',0.01),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/base_module.py:488: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n"
     ]
    }
   ],
   "source": [
    "mod.fit(train_iter, num_epoch = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAlternative approach\\nmod.fit(train_iter,\\n        initializer = mx.initializer.Xavier(rnd_type = 'gaussian', factor_type 'avg', magnitude = 1.),\\n        optimizer = 'adam',\\n        optimizer_params= {'learning_rate':0.001},\\n        eval_metric = mx.metric.MSE(),\\n        num_epoch = epoch)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Alternative approach\n",
    "mod.fit(train_iter,\n",
    "        initializer = mx.initializer.Xavier(rnd_type = 'gaussian', factor_type 'avg', magnitude = 1.),\n",
    "        optimizer = 'adam',\n",
    "        optimizer_params= {'learning_rate':0.001},\n",
    "        eval_metric = mx.metric.MSE(),\n",
    "        num_epoch = epoch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mse', 0.0072433468846004531), ('accuracy', 0.90000166577825158)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(train_iter, ['mse','acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 0\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 1\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 2\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 3\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 4\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 5\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 6\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 7\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 8\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 9\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 10\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 11\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 12\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 13\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 14\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 15\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 16\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 17\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 18\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 19\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 20\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 21\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 22\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 23\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 24\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 25\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 26\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 27\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 28\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 29\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 30\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 31\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 32\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 33\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 34\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 35\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 36\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 37\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 38\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 39\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 40\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 41\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 42\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 43\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 44\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 45\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 46\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 47\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 48\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 49\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 50\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 51\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 52\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 53\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 54\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 55\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 56\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 57\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 58\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 59\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 60\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 61\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 62\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 63\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 64\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 65\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 66\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 67\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 68\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 69\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 70\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 71\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 72\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 73\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 74\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 75\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 76\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 77\n",
      "Correct labels 128\n",
      "Predicted labels 128\n",
      "\n",
      "\n",
      "Batch Number: 78\n",
      "Correct labels 128\n",
      "Predicted labels 16\n",
      "\n",
      "\n",
      "Test Set accuracy {0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "correct_preds = 0\n",
    "for preds,i,batch in mod.iter_predict(test_iter):\n",
    "    label = batch.label[0].asnumpy().argmax(axis = 1)\n",
    "    pred_label = preds[0].asnumpy().argmax(axis = 1)\n",
    "    correct_preds += np.sum(pred_label == label)\n",
    "    print(\"Batch Number:\",i)\n",
    "    print(\"Correct labels\",len(label))\n",
    "    print(\"Predicted labels\",len(pred_label))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"Test Set accuracy {%2.2f}\" %(correct_preds/len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred_label == label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000%128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9\n",
      " 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1\n",
      " 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1\n",
      " 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7]\n",
      "\n",
      " [1 2 8 4 5 6 7 8 9 0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(label)\n",
    "print(\"\\n\",pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataDesc[softmax_label,(128, 10),<class 'numpy.float32'>,NCHW]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter.provide_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "    https://github.com/apache/incubator-mxnet/blob/master/example/module/mnist_mlp.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
