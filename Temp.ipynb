{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import mnist\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y,test_x, test_y = mnist.readmnist('data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/base_module.py:488: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n",
      "WARNING:root:optimizer already initialized, ignoring...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n",
      "['softmax_label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.9000016666666667), ('mse', 0.0064350389576672265)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting iterators\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(data = train_x, label = train_y, batch_size = batch_size,data_name = 'data', \n",
    "                               label_name = 'softmax_label',last_batch_handle = \"discard\", shuffle = True)\n",
    "data = mx.sym.Variable(\"data\")\n",
    "fc1 = mx.sym.FullyConnected(data = data, name =\"fc1\", num_hidden = 64, flatten = 1)\n",
    "relu1 = mx.sym.Activation(data = fc1, act_type = \"relu\", name = 'relu1')\n",
    "fc2 = mx.sym.FullyConnected(data = relu1, name = \"fc2\", num_hidden = 10, flatten = 1)\n",
    "out = mx.sym.SoftmaxOutput(data = fc2, name = \"softmax\")\n",
    "\n",
    "mod = mx.mod.Module(out,context = mx.cpu())\n",
    "print(mod.data_names)\n",
    "print(mod.label_names)\n",
    "\n",
    "mod.bind(data_shapes = train_iter.provide_data, label_shapes = train_iter.provide_label, for_training = True)\n",
    "mod.init_params(initializer = mx.init.Xavier(magnitude = 1.0))\n",
    "mod.init_optimizer(optimizer = \"sgd\", optimizer_params=(('learning_rate',0.01),), force_init = False)\n",
    "mod.fit(train_data = train_iter, eval_metric = \"accuracy\", num_epoch = epochs)\n",
    "mod.score(eval_data = train_iter, eval_metric = [\"acc\",\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = mx.io.NDArrayIter(data = test_x, labels = test_y, batch_size = batch_size, shuffle = False,\n",
    "                              last_batch_handle = \"discard\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
